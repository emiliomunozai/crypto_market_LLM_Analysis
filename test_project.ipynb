{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 0 - Requirementes and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Set autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Python modules\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# Data modules\n",
    "from src.data_handler.crypto_price_fetcher import get_crypto_data\n",
    "from src.data_handler.news_processor import process_news\n",
    "\n",
    "\n",
    "# Set logger\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 02:47:02,621 - INFO - Loading cached data from data/prices/BTC_USDT_hour_40days.csv\n",
      "2025-03-10 02:47:02,626 - INFO - Data retrieved successfully with 961 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 news articles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "<string>:9: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n"
     ]
    }
   ],
   "source": [
    "# load btc data\n",
    "btc_data = get_crypto_data('BTC', 'USDT', 'hour', 40)\n",
    "\n",
    "# Load 1000, events examples\n",
    "sample = 1000\n",
    "news = pd.read_csv('data/news/raw/news_btc.csv', nrows=sample)\n",
    "events = process_news(sample=sample)\n",
    "del(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-Improving LLM Agent with Multi-Memory Framework\n",
    "# Based on the provided diagram\n",
    "\n",
    "# Installing required packages\n",
    "!pip install langchain langchain-openai pydantic pandas matplotlib\n",
    "\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Any, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "# You need to set your API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# Define the data structures for our memory components\n",
    "class NewsItem(BaseModel):\n",
    "    \"\"\"A news item with its features.\"\"\"\n",
    "    content: str\n",
    "    date: str\n",
    "    source: str\n",
    "    category: str\n",
    "    sentiment: Optional[float] = 0.0\n",
    "    \n",
    "class PriceData(BaseModel):\n",
    "    \"\"\"Price data point.\"\"\"\n",
    "    asset: str\n",
    "    price: float\n",
    "    date: str\n",
    "    \n",
    "class Decision(BaseModel):\n",
    "    \"\"\"A decision made by the agent.\"\"\"\n",
    "    decision_id: str = Field(default_factory=lambda: f\"decision_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}\")\n",
    "    recommendation: str\n",
    "    confidence: float\n",
    "    reasoning: str\n",
    "    timestamp: str = Field(default_factory=lambda: datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    outcome: Optional[str] = None\n",
    "    reward: Optional[float] = None\n",
    "    \n",
    "class Fact(BaseModel):\n",
    "    \"\"\"A long term fact the agent has learned.\"\"\"\n",
    "    fact: str\n",
    "    source: str\n",
    "    confidence: float\n",
    "    category: str\n",
    "    timestamp: str = Field(default_factory=lambda: datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "# Memory Components as shown in the diagram\n",
    "class SensoryMemory:\n",
    "    \"\"\"\n",
    "    Sensory Memory: Most recent news + features and prices\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.news: List[NewsItem] = []\n",
    "        self.prices: List[PriceData] = []\n",
    "        self.max_items = 10  # Only keep the most recent items\n",
    "        \n",
    "    def add_news(self, news_item: NewsItem):\n",
    "        \"\"\"Add a news item to sensory memory.\"\"\"\n",
    "        self.news.append(news_item)\n",
    "        if len(self.news) > self.max_items:\n",
    "            self.news.pop(0)  # Remove oldest item\n",
    "            \n",
    "    def add_price(self, price_data: PriceData):\n",
    "        \"\"\"Add price data to sensory memory.\"\"\"\n",
    "        self.prices.append(price_data)\n",
    "        if len(self.prices) > self.max_items:\n",
    "            self.prices.pop(0)  # Remove oldest item\n",
    "            \n",
    "    def get_formatted(self) -> str:\n",
    "        \"\"\"Return formatted sensory memory for use in prompts.\"\"\"\n",
    "        news_str = \"\\n\".join([f\"- {item.date}: {item.content} (Source: {item.source}, Category: {item.category})\" \n",
    "                             for item in self.news])\n",
    "        price_str = \"\\n\".join([f\"- {item.date}: {item.asset} = ${item.price}\" \n",
    "                              for item in self.prices])\n",
    "        \n",
    "        return f\"## CURRENT SENSORY INPUT\\n### Recent News:\\n{news_str}\\n\\n### Current Prices:\\n{price_str}\"\n",
    "\n",
    "class ShortTermMemory:\n",
    "    \"\"\"\n",
    "    Short Term Memory: News + features (15 old news) and prices (averages and others)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.news: List[NewsItem] = []\n",
    "        self.prices: Dict[str, List[PriceData]] = {}  # Keyed by asset\n",
    "        self.max_news = 15\n",
    "        \n",
    "    def add_news(self, news_item: NewsItem):\n",
    "        \"\"\"Add a news item to short term memory.\"\"\"\n",
    "        self.news.append(news_item)\n",
    "        if len(self.news) > self.max_news:\n",
    "            self.news.pop(0)  # Remove oldest item\n",
    "            \n",
    "    def add_price(self, price_data: PriceData):\n",
    "        \"\"\"Add price data to short term memory.\"\"\"\n",
    "        if price_data.asset not in self.prices:\n",
    "            self.prices[price_data.asset] = []\n",
    "        self.prices[price_data.asset].append(price_data)\n",
    "        \n",
    "        # Keep only recent 30 prices per asset\n",
    "        if len(self.prices[price_data.asset]) > 30:\n",
    "            self.prices[price_data.asset].pop(0)\n",
    "            \n",
    "    def get_price_averages(self) -> Dict[str, float]:\n",
    "        \"\"\"Calculate average prices for each asset.\"\"\"\n",
    "        averages = {}\n",
    "        for asset, price_list in self.prices.items():\n",
    "            if price_list:\n",
    "                averages[asset] = sum(p.price for p in price_list) / len(price_list)\n",
    "        return averages\n",
    "    \n",
    "    def get_formatted(self) -> str:\n",
    "        \"\"\"Return formatted short term memory for use in prompts.\"\"\"\n",
    "        news_str = \"\\n\".join([f\"- {item.date}: {item.content}\" for item in self.news])\n",
    "        \n",
    "        # Calculate averages and create price summary\n",
    "        averages = self.get_price_averages()\n",
    "        price_summary = \"\\n\".join([f\"- {asset}: Average=${avg:.2f}, Latest=${self.prices[asset][-1].price:.2f}\"\n",
    "                                  for asset, avg in averages.items()])\n",
    "        \n",
    "        return f\"## SHORT TERM MEMORY\\n### Recent Historical News (Past few days):\\n{news_str}\\n\\n### Price Trends:\\n{price_summary}\"\n",
    "\n",
    "class ProceduralMemory:\n",
    "    \"\"\"\n",
    "    Procedural Memory: Procedures as a prompt on how to analyze and make decisions\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.procedures: Dict[str, str] = {\n",
    "            \"news_analysis\": \"\"\"\n",
    "To analyze news items:\n",
    "1. Identify key entities (companies, markets, sectors)\n",
    "2. Assess sentiment (positive, negative, neutral)\n",
    "3. Categorize impact (short-term, long-term, speculative)\n",
    "4. Cross-reference with other news for confirmation\n",
    "5. Evaluate source reliability\n",
    "            \"\"\",\n",
    "            \n",
    "            \"price_analysis\": \"\"\"\n",
    "To analyze price movements:\n",
    "1. Calculate percentage changes (daily, weekly)\n",
    "2. Identify trends (upward, downward, sideways)\n",
    "3. Compare to historical averages\n",
    "4. Check for correlation with news events\n",
    "5. Note unusual volume or volatility\n",
    "            \"\"\",\n",
    "            \n",
    "            \"decision_making\": \"\"\"\n",
    "To make recommendation decisions:\n",
    "1. Assess all available news and price data\n",
    "2. Consider short-term and long-term implications\n",
    "3. Evaluate risk factors\n",
    "4. Form a hypothesis backed by specific data points\n",
    "5. Assign a confidence level based on data quality and consistency\n",
    "6. Make a clear recommendation with supporting rationale\n",
    "            \"\"\"\n",
    "        }\n",
    "        \n",
    "    def add_procedure(self, name: str, procedure: str):\n",
    "        \"\"\"Add a new procedure or update an existing one.\"\"\"\n",
    "        self.procedures[name] = procedure\n",
    "        \n",
    "    def get_procedure(self, name: str) -> str:\n",
    "        \"\"\"Get a specific procedure by name.\"\"\"\n",
    "        return self.procedures.get(name, \"Procedure not found.\")\n",
    "    \n",
    "    def get_formatted(self) -> str:\n",
    "        \"\"\"Return all procedures formatted for use in prompts.\"\"\"\n",
    "        procedures_str = \"\\n\\n\".join([f\"### {name.upper()}:\\n{proc}\" \n",
    "                                     for name, proc in self.procedures.items()])\n",
    "        \n",
    "        return f\"## PROCEDURAL MEMORY - HOW TO ANALYZE AND DECIDE\\n{procedures_str}\"\n",
    "\n",
    "class LongTermMemory:\n",
    "    \"\"\"\n",
    "    Long Term Memory: Facts that the agent has learned\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.facts: List[Fact] = []\n",
    "        \n",
    "    def add_fact(self, fact: Fact):\n",
    "        \"\"\"Add a new fact to long term memory.\"\"\"\n",
    "        self.facts.append(fact)\n",
    "        \n",
    "    def get_facts_by_category(self, category: str) -> List[Fact]:\n",
    "        \"\"\"Retrieve facts by category.\"\"\"\n",
    "        return [f for f in self.facts if f.category == category]\n",
    "    \n",
    "    def get_formatted(self, max_facts: int = 15) -> str:\n",
    "        \"\"\"Return formatted facts for use in prompts, limited to most relevant.\"\"\"\n",
    "        # In a real system, you would implement relevance ranking\n",
    "        # For simplicity, we'll just take the most recent facts\n",
    "        recent_facts = sorted(self.facts, key=lambda x: x.timestamp, reverse=True)[:max_facts]\n",
    "        \n",
    "        facts_str = \"\\n\".join([f\"- {fact.fact} (Confidence: {fact.confidence}, Source: {fact.source})\" \n",
    "                              for fact in recent_facts])\n",
    "        \n",
    "        return f\"## LONG TERM MEMORY - ESTABLISHED FACTS\\n{facts_str}\"\n",
    "\n",
    "class AutobiographicalMemory:\n",
    "    \"\"\"\n",
    "    Autobiographical Memory: Logs the agent's own decision history and outcomes\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.decisions: List[Decision] = []\n",
    "        \n",
    "    def add_decision(self, decision: Decision):\n",
    "        \"\"\"Add a new decision to autobiographical memory.\"\"\"\n",
    "        self.decisions.append(decision)\n",
    "        \n",
    "    def update_outcome(self, decision_id: str, outcome: str, reward: float):\n",
    "        \"\"\"Update a decision with its outcome and reward.\"\"\"\n",
    "        for decision in self.decisions:\n",
    "            if decision.decision_id == decision_id:\n",
    "                decision.outcome = outcome\n",
    "                decision.reward = reward\n",
    "                break\n",
    "                \n",
    "    def get_formatted(self, max_decisions: int = 10) -> str:\n",
    "        \"\"\"Return formatted decision history for use in prompts.\"\"\"\n",
    "        # Get the most recent decisions\n",
    "        recent_decisions = sorted(self.decisions, key=lambda x: x.timestamp, reverse=True)[:max_decisions]\n",
    "        \n",
    "        decisions_str = \"\\n\".join([\n",
    "            f\"- Decision {d.decision_id}: {d.recommendation} (Confidence: {d.confidence})\\n  \"\n",
    "            f\"Reasoning: {d.reasoning}\\n  \"\n",
    "            f\"Outcome: {d.outcome or 'Pending'}, Reward: {d.reward or 'N/A'}\"\n",
    "            for d in recent_decisions\n",
    "        ])\n",
    "        \n",
    "        return f\"## AUTOBIOGRAPHICAL MEMORY - PREVIOUS DECISIONS AND OUTCOMES\\n{decisions_str}\"\n",
    "\n",
    "class WorkingMemory:\n",
    "    \"\"\"\n",
    "    Working Memory: ReAct framework for reasoning and acting\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.thought_process: List[str] = []\n",
    "        self.max_thoughts = 5  # Only keep recent thought steps\n",
    "        \n",
    "    def add_thought(self, thought: str):\n",
    "        \"\"\"Add a thought to the reasoning process.\"\"\"\n",
    "        self.thought_process.append(thought)\n",
    "        if len(self.thought_process) > self.max_thoughts:\n",
    "            self.thought_process.pop(0)\n",
    "            \n",
    "    def clear(self):\n",
    "        \"\"\"Clear working memory for a new reasoning session.\"\"\"\n",
    "        self.thought_process = []\n",
    "        \n",
    "    def get_formatted(self) -> str:\n",
    "        \"\"\"Return formatted working memory for use in prompts.\"\"\"\n",
    "        thoughts_str = \"\\n\".join([f\"{i+1}. {thought}\" for i, thought in enumerate(self.thought_process)])\n",
    "        \n",
    "        return f\"## WORKING MEMORY - CURRENT REASONING PROCESS\\n{thoughts_str}\"\n",
    "\n",
    "class ProspectiveMemory:\n",
    "    \"\"\"\n",
    "    Prospective Memory: Future considerations to keep in mind\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.considerations: List[str] = []\n",
    "        \n",
    "    def add_consideration(self, consideration: str):\n",
    "        \"\"\"Add a consideration for future decisions.\"\"\"\n",
    "        self.considerations.append(consideration)\n",
    "        \n",
    "    def get_formatted(self) -> str:\n",
    "        \"\"\"Return formatted prospective memory for use in prompts.\"\"\"\n",
    "        if not self.considerations:\n",
    "            return \"## PROSPECTIVE MEMORY - FUTURE CONSIDERATIONS\\nNo specific future considerations at this time.\"\n",
    "            \n",
    "        considerations_str = \"\\n\".join([f\"- {consideration}\" for consideration in self.considerations])\n",
    "        \n",
    "        return f\"## PROSPECTIVE MEMORY - FUTURE CONSIDERATIONS\\n{considerations_str}\"\n",
    "\n",
    "# The main LLM Agent that integrates all memory components\n",
    "class LLMAgent:\n",
    "    def __init__(self, model_name=\"gpt-3.5-turbo\"):\n",
    "        # Initialize memory components\n",
    "        self.sensory_memory = SensoryMemory()\n",
    "        self.short_term_memory = ShortTermMemory()\n",
    "        self.procedural_memory = ProceduralMemory()\n",
    "        self.long_term_memory = LongTermMemory()\n",
    "        self.autobiographical_memory = AutobiographicalMemory()\n",
    "        self.working_memory = WorkingMemory()\n",
    "        self.prospective_memory = ProspectiveMemory()\n",
    "        \n",
    "        # Initialize LLM\n",
    "        self.llm = ChatOpenAI(model_name=model_name, temperature=0.7)\n",
    "        \n",
    "        # Define the agent's system prompt\n",
    "        self.system_prompt = \"\"\"You are an advanced AI financial analyst with multiple memory systems.\n",
    "Your goal is to provide investment recommendations based on news and price data.\n",
    "As you process information, you will build knowledge and learn from your past decisions.\n",
    "\n",
    "You should use the different memory systems to inform your analysis and recommendations.\n",
    "Think step by step and show your reasoning process before making final recommendations.\n",
    "\"\"\"\n",
    "\n",
    "    def _build_full_prompt(self, query: str) -> str:\n",
    "        \"\"\"Build a complete prompt combining all memory components.\"\"\"\n",
    "        prompt_parts = [\n",
    "            self.sensory_memory.get_formatted(),\n",
    "            self.short_term_memory.get_formatted(),\n",
    "            self.procedural_memory.get_formatted(),\n",
    "            self.long_term_memory.get_formatted(),\n",
    "            self.autobiographical_memory.get_formatted(),\n",
    "            self.working_memory.get_formatted(),\n",
    "            self.prospective_memory.get_formatted(),\n",
    "            f\"\\n## NEW QUERY\\n{query}\\n\\n## RESPONSE\\nLet me think through this step by step:\"\n",
    "        ]\n",
    "        \n",
    "        return \"\\n\\n\".join(prompt_parts)\n",
    "    \n",
    "    def react_step(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        Implement the ReAct framework for a single step of reasoning.\n",
    "        \"\"\"\n",
    "        # Build the prompt with all memory components\n",
    "        full_prompt = self._build_full_prompt(query)\n",
    "        \n",
    "        # Get response from LLM\n",
    "        response = self.llm.invoke([HumanMessage(content=full_prompt)])\n",
    "        \n",
    "        # Add the reasoning to working memory\n",
    "        self.working_memory.add_thought(response.content)\n",
    "        \n",
    "        return response.content\n",
    "    \n",
    "    def make_recommendation(self, query: str) -> Decision:\n",
    "        \"\"\"\n",
    "        Make a recommendation based on all available memory and the current query.\n",
    "        \"\"\"\n",
    "        # Clear working memory for fresh reasoning\n",
    "        self.working_memory.clear()\n",
    "        \n",
    "        # First, use react steps to build reasoning\n",
    "        self.react_step(f\"Analyze the latest news and price data to answer: {query}\")\n",
    "        \n",
    "        # Final recommendation prompt with specific format request\n",
    "        recommendation_prompt = f\"\"\"\n",
    "Based on your previous analysis, make a final recommendation regarding: {query}\n",
    "\n",
    "Your response should be structured as:\n",
    "RECOMMENDATION: [Clear statement of recommendation]\n",
    "CONFIDENCE: [Numeric value between 0-1]\n",
    "REASONING: [Concise summary of key factors that led to this recommendation]\n",
    "\"\"\"\n",
    "        \n",
    "        # Get structured recommendation\n",
    "        full_prompt = self._build_full_prompt(recommendation_prompt)\n",
    "        recommendation_response = self.llm.invoke([HumanMessage(content=full_prompt)])\n",
    "        \n",
    "        # Parse the response to extract recommendation, confidence, and reasoning\n",
    "        response_text = recommendation_response.content\n",
    "        \n",
    "        # Simple parsing - in a production system you'd use more robust methods\n",
    "        recommendation = \"\"\n",
    "        confidence = 0.5  # Default\n",
    "        reasoning = \"\"\n",
    "        \n",
    "        for line in response_text.split('\\n'):\n",
    "            if line.startswith(\"RECOMMENDATION:\"):\n",
    "                recommendation = line.replace(\"RECOMMENDATION:\", \"\").strip()\n",
    "            elif line.startswith(\"CONFIDENCE:\"):\n",
    "                confidence_str = line.replace(\"CONFIDENCE:\", \"\").strip()\n",
    "                try:\n",
    "                    confidence = float(confidence_str)\n",
    "                except ValueError:\n",
    "                    # Handle text confidence levels\n",
    "                    if \"high\" in confidence_str.lower():\n",
    "                        confidence = 0.8\n",
    "                    elif \"medium\" in confidence_str.lower():\n",
    "                        confidence = 0.5\n",
    "                    elif \"low\" in confidence_str.lower():\n",
    "                        confidence = 0.3\n",
    "            elif line.startswith(\"REASONING:\"):\n",
    "                reasoning = line.replace(\"REASONING:\", \"\").strip()\n",
    "        \n",
    "        # Create a decision object\n",
    "        decision = Decision(\n",
    "            recommendation=recommendation,\n",
    "            confidence=confidence,\n",
    "            reasoning=reasoning\n",
    "        )\n",
    "        \n",
    "        # Add to autobiographical memory\n",
    "        self.autobiographical_memory.add_decision(decision)\n",
    "        \n",
    "        return decision\n",
    "    \n",
    "    def process_feedback(self, decision_id: str, outcome: str, reward: float):\n",
    "        \"\"\"\n",
    "        Process feedback on a past decision and update memories accordingly.\n",
    "        \"\"\"\n",
    "        # Update the decision in autobiographical memory\n",
    "        self.autobiographical_memory.update_outcome(decision_id, outcome, reward)\n",
    "        \n",
    "        # Use the feedback to potentially learn new facts\n",
    "        feedback_prompt = f\"\"\"\n",
    "I received feedback on my recommendation (ID: {decision_id}):\n",
    "Outcome: {outcome}\n",
    "Reward: {reward}\n",
    "\n",
    "Based on this feedback, what's one important fact I should remember for future decisions?\n",
    "Format your response as:\n",
    "NEW FACT: [concise statement of a fact to remember]\n",
    "CATEGORY: [category for this fact]\n",
    "CONFIDENCE: [numeric value between 0-1]\n",
    "\"\"\"\n",
    "        \n",
    "        full_prompt = self._build_full_prompt(feedback_prompt)\n",
    "        learning_response = self.llm.invoke([HumanMessage(content=full_prompt)])\n",
    "        \n",
    "        # Parse the response to extract the new fact\n",
    "        response_text = learning_response.content\n",
    "        \n",
    "        fact_text = \"\"\n",
    "        category = \"general\"\n",
    "        confidence = 0.5\n",
    "        \n",
    "        for line in response_text.split('\\n'):\n",
    "            if line.startswith(\"NEW FACT:\"):\n",
    "                fact_text = line.replace(\"NEW FACT:\", \"\").strip()\n",
    "            elif line.startswith(\"CATEGORY:\"):\n",
    "                category = line.replace(\"CATEGORY:\", \"\").strip()\n",
    "            elif line.startswith(\"CONFIDENCE:\"):\n",
    "                try:\n",
    "                    confidence = float(line.replace(\"CONFIDENCE:\", \"\").strip())\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        \n",
    "        if fact_text:\n",
    "            # Add new fact to long-term memory\n",
    "            new_fact = Fact(\n",
    "                fact=fact_text,\n",
    "                source=f\"Feedback on decision {decision_id}\",\n",
    "                confidence=confidence,\n",
    "                category=category\n",
    "            )\n",
    "            self.long_term_memory.add_fact(new_fact)\n",
    "            \n",
    "            # Also add a consideration to prospective memory\n",
    "            self.prospective_memory.add_consideration(\n",
    "                f\"Consider the outcome of similar situations to decision {decision_id} ({fact_text})\"\n",
    "            )\n",
    "        \n",
    "        return learning_response.content\n",
    "    \n",
    "    def update_with_news(self, news_items: List[NewsItem]):\n",
    "        \"\"\"Update memory with new news items.\"\"\"\n",
    "        for item in news_items:\n",
    "            # Add to sensory memory\n",
    "            self.sensory_memory.add_news(item)\n",
    "            \n",
    "            # Add to short-term memory\n",
    "            self.short_term_memory.add_news(item)\n",
    "    \n",
    "    def update_with_prices(self, price_data: List[PriceData]):\n",
    "        \"\"\"Update memory with new price data.\"\"\"\n",
    "        for item in price_data:\n",
    "            # Add to sensory memory\n",
    "            self.sensory_memory.add_price(item)\n",
    "            \n",
    "            # Add to short-term memory\n",
    "            self.short_term_memory.add_price(item)\n",
    "\n",
    "# Example usage of the agent\n",
    "def generate_sample_data():\n",
    "    \"\"\"Generate sample news and price data for demonstration.\"\"\"\n",
    "    news_items = [\n",
    "        NewsItem(\n",
    "            content=\"Federal Reserve hints at potential interest rate cut next month\",\n",
    "            date=\"2023-09-01\",\n",
    "            source=\"Financial Times\",\n",
    "            category=\"Monetary Policy\"\n",
    "        ),\n",
    "        NewsItem(\n",
    "            content=\"Tech stocks rally as investors anticipate lower borrowing costs\",\n",
    "            date=\"2023-09-02\",\n",
    "            source=\"Bloomberg\",\n",
    "            category=\"Markets\"\n",
    "        ),\n",
    "        NewsItem(\n",
    "            content=\"Oil prices drop 3% on weak demand forecasts\",\n",
    "            date=\"2023-09-03\",\n",
    "            source=\"Reuters\",\n",
    "            category=\"Commodities\"\n",
    "        ),\n",
    "        NewsItem(\n",
    "            content=\"Major retailer reports better than expected Q3 earnings\",\n",
    "            date=\"2023-09-04\",\n",
    "            source=\"CNBC\",\n",
    "            category=\"Earnings\"\n",
    "        ),\n",
    "        NewsItem(\n",
    "            content=\"Housing starts decline for third consecutive month\",\n",
    "            date=\"2023-09-05\",\n",
    "            source=\"Wall Street Journal\",\n",
    "            category=\"Economic Data\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    price_data = [\n",
    "        PriceData(asset=\"SPY\", price=450.23, date=\"2023-09-01\"),\n",
    "        PriceData(asset=\"SPY\", price=452.78, date=\"2023-09-02\"),\n",
    "        PriceData(asset=\"SPY\", price=453.15, date=\"2023-09-03\"),\n",
    "        PriceData(asset=\"SPY\", price=451.89, date=\"2023-09-04\"),\n",
    "        PriceData(asset=\"SPY\", price=454.20, date=\"2023-09-05\"),\n",
    "        PriceData(asset=\"QQQ\", price=370.45, date=\"2023-09-01\"),\n",
    "        PriceData(asset=\"QQQ\", price=375.23, date=\"2023-09-02\"),\n",
    "        PriceData(asset=\"QQQ\", price=378.67, date=\"2023-09-03\"),\n",
    "        PriceData(asset=\"QQQ\", price=380.12, date=\"2023-09-04\"),\n",
    "        PriceData(asset=\"QQQ\", price=382.98, date=\"2023-09-05\"),\n",
    "        PriceData(asset=\"XLE\", price=88.23, date=\"2023-09-01\"),\n",
    "        PriceData(asset=\"XLE\", price=87.45, date=\"2023-09-02\"),\n",
    "        PriceData(asset=\"XLE\", price=85.67, date=\"2023-09-03\"),\n",
    "        PriceData(asset=\"XLE\", price=84.32, date=\"2023-09-04\"),\n",
    "        PriceData(asset=\"XLE\", price=83.78, date=\"2023-09-05\")\n",
    "    ]\n",
    "    \n",
    "    return news_items, price_data\n",
    "\n",
    "# Add some sample facts to long-term memory\n",
    "def populate_long_term_memory(agent: LLMAgent):\n",
    "    \"\"\"Add some sample facts to the agent's long-term memory.\"\"\"\n",
    "    sample_facts = [\n",
    "        Fact(\n",
    "            fact=\"Interest rate cuts typically lead to rallies in growth stocks\",\n",
    "            source=\"Historical market analysis\",\n",
    "            confidence=0.85,\n",
    "            category=\"Monetary Policy\"\n",
    "        ),\n",
    "        Fact(\n",
    "            fact=\"Energy sector tends to underperform in periods of weak global demand\",\n",
    "            source=\"Sector rotation studies\",\n",
    "            confidence=0.75,\n",
    "            category=\"Sectors\"\n",
    "        ),\n",
    "        Fact(\n",
    "            fact=\"Housing data is a leading indicator for consumer discretionary spending\",\n",
    "            source=\"Economic research\",\n",
    "            confidence=0.7,\n",
    "            category=\"Economic Indicators\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    for fact in sample_facts:\n",
    "        agent.long_term_memory.add_fact(fact)\n",
    "\n",
    "# Simulate running the agent\n",
    "def run_simulation():\n",
    "    \"\"\"Run a simulation of the agent over multiple days.\"\"\"\n",
    "    # Initialize the agent\n",
    "    agent = LLMAgent()\n",
    "    \n",
    "    # Generate sample data\n",
    "    news_items, price_data = generate_sample_data()\n",
    "    \n",
    "    # Add sample facts\n",
    "    populate_long_term_memory(agent)\n",
    "    \n",
    "    # Update with initial data\n",
    "    agent.update_with_news(news_items)\n",
    "    agent.update_with_prices(price_data)\n",
    "    \n",
    "    # Make initial recommendation\n",
    "    print(\"MAKING INITIAL RECOMMENDATION\")\n",
    "    decision = agent.make_recommendation(\"Should investors increase their allocation to technology stocks given current market conditions?\")\n",
    "    \n",
    "    print(f\"\\nRECOMMENDATION: {decision.recommendation}\")\n",
    "    print(f\"CONFIDENCE: {decision.confidence}\")\n",
    "    print(f\"REASONING: {decision.reasoning}\")\n",
    "    print(f\"DECISION ID: {decision.decision_id}\")\n",
    "    \n",
    "    # Simulate feedback\n",
    "    print(\"\\n\\nPROCESSING FEEDBACK\")\n",
    "    learning_output = agent.process_feedback(\n",
    "        decision_id=decision.decision_id,\n",
    "        outcome=\"The recommendation was correct. Technology stocks rose 2.5% in the following week.\",\n",
    "        reward=0.8\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nLEARNING OUTPUT: {learning_output}\")\n",
    "    \n",
    "    # Add new data (simulating next day)\n",
    "    print(\"\\n\\nUPDATING WITH NEW DATA\")\n",
    "    new_news = [\n",
    "        NewsItem(\n",
    "            content=\"Inflation data comes in lower than expected\",\n",
    "            date=\"2023-09-06\",\n",
    "            source=\"Bloomberg\",\n",
    "            category=\"Economic Data\"\n",
    "        ),\n",
    "        NewsItem(\n",
    "            content=\"Major tech company announces new AI initiative\",\n",
    "            date=\"2023-09-06\",\n",
    "            source=\"TechCrunch\",\n",
    "            category=\"Technology\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    new_prices = [\n",
    "        PriceData(asset=\"SPY\", price=456.75, date=\"2023-09-06\"),\n",
    "        PriceData(asset=\"QQQ\", price=385.43, date=\"2023-09-06\"),\n",
    "        PriceData(asset=\"XLE\", price=82.56, date=\"2023-09-06\")\n",
    "    ]\n",
    "    \n",
    "    agent.update_with_news(new_news)\n",
    "    agent.update_with_prices(new_prices)\n",
    "    \n",
    "    # Make a new recommendation\n",
    "    print(\"\\nMAKING UPDATED RECOMMENDATION\")\n",
    "    new_decision = agent.make_recommendation(\"Given the latest inflation data and tech announcement, should investors further increase their allocation to growth stocks?\")\n",
    "    \n",
    "    print(f\"\\nRECOMMENDATION: {new_decision.recommendation}\")\n",
    "    print(f\"CONFIDENCE: {new_decision.confidence}\")\n",
    "    print(f\"REASONING: {new_decision.reasoning}\")\n",
    "    print(f\"DECISION ID: {new_decision.decision_id}\")\n",
    "    \n",
    "    # Display memory contents for demonstration\n",
    "    print(\"\\n\\nMEMORY CONTENTS:\")\n",
    "    print(\"\\nSENSORY MEMORY:\")\n",
    "    print(agent.sensory_memory.get_formatted())\n",
    "    \n",
    "    print(\"\\nSHORT TERM MEMORY:\")\n",
    "    print(agent.short_term_memory.get_formatted())\n",
    "    \n",
    "    print(\"\\nLONG TERM MEMORY:\")\n",
    "    print(agent.long_term_memory.get_formatted())\n",
    "    \n",
    "    print(\"\\nAUTOBIOGRAPHICAL MEMORY:\")\n",
    "    print(agent.autobiographical_memory.get_formatted())\n",
    "    \n",
    "    print(\"\\nPROSPECTIVE MEMORY:\")\n",
    "    print(agent.prospective_memory.get_formatted())\n",
    "    \n",
    "    return agent\n",
    "\n",
    "# Run simulation if this script is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    agent = run_simulation()\n",
    "    \n",
    "    # Visualize the agent's decision history\n",
    "    decisions = agent.autobiographical_memory.decisions\n",
    "    if decisions:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        decision_ids = [d.decision_id[-6:] for d in decisions]  # Use shortened IDs for display\n",
    "        confidence_values = [d.confidence for d in decisions]\n",
    "        rewards = [d.reward if d.reward is not None else 0 for d in decisions]\n",
    "        \n",
    "        bar_width = 0.35\n",
    "        index = range(len(decisions))\n",
    "        \n",
    "        plt.bar([i - bar_width/2 for i in index], confidence_values, bar_width, label='Confidence')\n",
    "        plt.bar([i + bar_width/2 for i in index], rewards, bar_width, label='Reward')\n",
    "        \n",
    "        plt.xlabel('Decisions')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title('Agent Decision Confidence vs Rewards')\n",
    "        plt.xticks(index, decision_ids)\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
