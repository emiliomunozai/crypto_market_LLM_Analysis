{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 0 - Requirementes and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Set autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Python modules\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# Data modules\n",
    "from src.data_handler.crypto_price_fetcher import get_crypto_data\n",
    "from src.data_handler.news_processor import process_news\n",
    "\n",
    "\n",
    "# Set logger\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 03:14:39,042 - INFO - Fetching BTC/USDT hourly data from 2019-01-01...\n",
      "2025-03-10 03:14:39,872 - INFO - Successfully fetched 2001 records\n",
      "2025-03-10 03:14:39,887 - INFO - Data saved to data/prices/BTC_USDT_hour_2019-01-01_2260days.csv\n"
     ]
    }
   ],
   "source": [
    "# Get Prices\n",
    "btc_data = get_crypto_data('BTC', 'USDT', 'hour', day=1, month=1, year=2019)\n",
    "\n",
    "# Get News\n",
    "news = pd.read_csv('data/news/raw/news_btc.csv', nrows=sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 news articles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "# Build events\n",
    "\n",
    "#% Proccess news\n",
    "import pandas as pd\n",
    "sample = 1000 # first 1000 starting in march 2019\n",
    "events = process_news(sample=sample)\n",
    "events['date'] = pd.to_datetime(events['date'])\n",
    "events = events.sort_values(by='date')\n",
    "\n",
    "# Drop events with nan in text column\n",
    "events = events.dropna(subset=['text'])\n",
    "\n",
    "#% Join events with stock data based on date use closes time reference\n",
    "events = pd.merge(events, btc_data, how='left', left_on='date', right_on='timestamp')\n",
    "\n",
    "# Create a new column with the next day's close price\n",
    "events['next_t_close'] = events['close'].shift(-100)\n",
    "\n",
    "# Calculate close price rolling stats 7 ts, 30 ts, 90 ts\n",
    "events['close_7'] = events['close'].rolling(7).mean()\n",
    "events['close_30'] = events['close'].rolling(30).mean()\n",
    "events['close_90'] = events['close'].rolling(90).mean()\n",
    "\n",
    "# Drop first 100 rows\n",
    "events = events.dropna(subset=['next_t_close'])\n",
    "events = events.dropna(subset=['close_90'])\n",
    "\n",
    "# if next_day_close is lower than close, then 1 else 0\n",
    "events['target'] = events.apply(lambda x: \"Long\" if x['next_t_close'] > x['close'] else \"short\", axis=1)\n",
    "\n",
    "# calculate the difference between next_day_close and close\n",
    "events['diff_perc'] = ((events['next_t_close'] / events['close']) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing required packages (if not already installed)\n",
    "# !pip install langchain langchain-openai pydantic pandas matplotlib\n",
    "\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Any, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "# Set your API key for OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# --- Data Structures ---\n",
    "\n",
    "class NewsItem(BaseModel):\n",
    "    \"\"\"A news item with its features.\"\"\"\n",
    "    content: str\n",
    "    date: str\n",
    "    source: str\n",
    "    category: str\n",
    "    sentiment: Optional[float] = 0.0\n",
    "\n",
    "class PriceData(BaseModel):\n",
    "    \"\"\"Price data point with extended fields.\"\"\"\n",
    "    asset: str\n",
    "    price: float\n",
    "    date: str\n",
    "    open: Optional[float] = None\n",
    "    high: Optional[float] = None\n",
    "    low: Optional[float] = None\n",
    "    volume: Optional[float] = None\n",
    "    next_t_close: Optional[float] = None\n",
    "    close_7: Optional[float] = None\n",
    "    close_30: Optional[float] = None\n",
    "    close_90: Optional[float] = None\n",
    "    target: Optional[str] = None\n",
    "    diff_perc: Optional[float] = None\n",
    "\n",
    "class Decision(BaseModel):\n",
    "    \"\"\"A decision made by the agent.\"\"\"\n",
    "    decision_id: str = Field(default_factory=lambda: f\"decision_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}\")\n",
    "    recommendation: str\n",
    "    confidence: float\n",
    "    reasoning: str\n",
    "    timestamp: str = Field(default_factory=lambda: datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    outcome: Optional[str] = None\n",
    "    reward: Optional[float] = None\n",
    "\n",
    "class Fact(BaseModel):\n",
    "    \"\"\"A long term fact the agent has learned.\"\"\"\n",
    "    fact: str\n",
    "    source: str\n",
    "    confidence: float\n",
    "    category: str\n",
    "    timestamp: str = Field(default_factory=lambda: datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "# --- Memory Components ---\n",
    "\n",
    "class SensoryMemory:\n",
    "    def __init__(self):\n",
    "        self.news: List[NewsItem] = []\n",
    "        self.prices: List[PriceData] = []\n",
    "        self.max_items = 10  # Keep only the most recent items\n",
    "        \n",
    "    def add_news(self, news_item: NewsItem):\n",
    "        self.news.append(news_item)\n",
    "        if len(self.news) > self.max_items:\n",
    "            self.news.pop(0)\n",
    "            \n",
    "    def add_price(self, price_data: PriceData):\n",
    "        self.prices.append(price_data)\n",
    "        if len(self.prices) > self.max_items:\n",
    "            self.prices.pop(0)\n",
    "            \n",
    "    def get_formatted(self) -> str:\n",
    "        news_str = \"\\n\".join([f\"- {item.date}: {item.content} (Source: {item.source}, Category: {item.category})\" \n",
    "                             for item in self.news])\n",
    "        price_str = \"\\n\".join([f\"- {item.date}: {item.asset} close=${item.price}\" \n",
    "                              for item in self.prices])\n",
    "        return f\"## CURRENT SENSORY INPUT\\n### Recent News:\\n{news_str}\\n\\n### Current Prices:\\n{price_str}\"\n",
    "\n",
    "class ShortTermMemory:\n",
    "    def __init__(self):\n",
    "        self.news: List[NewsItem] = []\n",
    "        self.prices: Dict[str, List[PriceData]] = {}  # Keyed by asset\n",
    "        self.max_news = 15\n",
    "        \n",
    "    def add_news(self, news_item: NewsItem):\n",
    "        self.news.append(news_item)\n",
    "        if len(self.news) > self.max_news:\n",
    "            self.news.pop(0)\n",
    "            \n",
    "    def add_price(self, price_data: PriceData):\n",
    "        if price_data.asset not in self.prices:\n",
    "            self.prices[price_data.asset] = []\n",
    "        self.prices[price_data.asset].append(price_data)\n",
    "        if len(self.prices[price_data.asset]) > 30:\n",
    "            self.prices[price_data.asset].pop(0)\n",
    "            \n",
    "    def get_price_averages(self) -> Dict[str, float]:\n",
    "        averages = {}\n",
    "        for asset, price_list in self.prices.items():\n",
    "            if price_list:\n",
    "                averages[asset] = sum(p.price for p in price_list) / len(price_list)\n",
    "        return averages\n",
    "    \n",
    "    def get_formatted(self) -> str:\n",
    "        news_str = \"\\n\".join([f\"- {item.date}: {item.content}\" for item in self.news])\n",
    "        averages = self.get_price_averages()\n",
    "        price_summary = \"\\n\".join([f\"- {asset}: Average=${avg:.2f}, Latest=${self.prices[asset][-1].price:.2f}\"\n",
    "                                  for asset, avg in averages.items()])\n",
    "        return f\"## SHORT TERM MEMORY\\n### Recent Historical News (Past few days):\\n{news_str}\\n\\n### Price Trends:\\n{price_summary}\"\n",
    "\n",
    "class ProceduralMemory:\n",
    "    def __init__(self):\n",
    "        self.procedures: Dict[str, str] = {\n",
    "            \"news_analysis\": \"\"\"\n",
    "To analyze news items:\n",
    "1. Identify key entities (companies, markets, sectors)\n",
    "2. Assess sentiment (positive, negative, neutral)\n",
    "3. Categorize impact (short-term, long-term, speculative)\n",
    "4. Cross-reference with other news for confirmation\n",
    "5. Evaluate source reliability\n",
    "            \"\"\",\n",
    "            \"price_analysis\": \"\"\"\n",
    "To analyze price movements:\n",
    "1. Calculate percentage changes (daily, weekly)\n",
    "2. Identify trends (upward, downward, sideways)\n",
    "3. Compare to historical averages\n",
    "4. Check for correlation with news events\n",
    "5. Note unusual volume or volatility\n",
    "            \"\"\",\n",
    "            \"decision_making\": \"\"\"\n",
    "To make recommendation decisions:\n",
    "1. Assess all available news and price data\n",
    "2. Consider short-term and long-term implications\n",
    "3. Evaluate risk factors\n",
    "4. Form a hypothesis backed by specific data points\n",
    "5. Assign a confidence level based on data quality and consistency\n",
    "6. Make a clear recommendation with supporting rationale\n",
    "            \"\"\"\n",
    "        }\n",
    "        \n",
    "    def add_procedure(self, name: str, procedure: str):\n",
    "        self.procedures[name] = procedure\n",
    "        \n",
    "    def get_procedure(self, name: str) -> str:\n",
    "        return self.procedures.get(name, \"Procedure not found.\")\n",
    "    \n",
    "    def get_formatted(self) -> str:\n",
    "        procedures_str = \"\\n\\n\".join([f\"### {name.upper()}:\\n{proc}\" \n",
    "                                     for name, proc in self.procedures.items()])\n",
    "        return f\"## PROCEDURAL MEMORY - HOW TO ANALYZE AND DECIDE\\n{procedures_str}\"\n",
    "\n",
    "class LongTermMemory:\n",
    "    def __init__(self):\n",
    "        self.facts: List[Fact] = []\n",
    "        \n",
    "    def add_fact(self, fact: Fact):\n",
    "        self.facts.append(fact)\n",
    "        \n",
    "    def get_facts_by_category(self, category: str) -> List[Fact]:\n",
    "        return [f for f in self.facts if f.category == category]\n",
    "    \n",
    "    def get_formatted(self, max_facts: int = 15) -> str:\n",
    "        recent_facts = sorted(self.facts, key=lambda x: x.timestamp, reverse=True)[:max_facts]\n",
    "        facts_str = \"\\n\".join([f\"- {fact.fact} (Confidence: {fact.confidence}, Source: {fact.source})\" \n",
    "                              for fact in recent_facts])\n",
    "        return f\"## LONG TERM MEMORY - ESTABLISHED FACTS\\n{facts_str}\"\n",
    "\n",
    "class AutobiographicalMemory:\n",
    "    def __init__(self):\n",
    "        self.decisions: List[Decision] = []\n",
    "        \n",
    "    def add_decision(self, decision: Decision):\n",
    "        self.decisions.append(decision)\n",
    "        \n",
    "    def update_outcome(self, decision_id: str, outcome: str, reward: float):\n",
    "        for decision in self.decisions:\n",
    "            if decision.decision_id == decision_id:\n",
    "                decision.outcome = outcome\n",
    "                decision.reward = reward\n",
    "                break\n",
    "                \n",
    "    def get_formatted(self, max_decisions: int = 10) -> str:\n",
    "        recent_decisions = sorted(self.decisions, key=lambda x: x.timestamp, reverse=True)[:max_decisions]\n",
    "        decisions_str = \"\\n\".join([\n",
    "            f\"- Decision {d.decision_id}: {d.recommendation} (Confidence: {d.confidence})\\n  \"\n",
    "            f\"Reasoning: {d.reasoning}\\n  Outcome: {d.outcome or 'Pending'}, Reward: {d.reward or 'N/A'}\"\n",
    "            for d in recent_decisions\n",
    "        ])\n",
    "        return f\"## AUTOBIOGRAPHICAL MEMORY - PREVIOUS DECISIONS AND OUTCOMES\\n{decisions_str}\"\n",
    "\n",
    "class WorkingMemory:\n",
    "    def __init__(self):\n",
    "        self.thought_process: List[str] = []\n",
    "        self.max_thoughts = 5\n",
    "        \n",
    "    def add_thought(self, thought: str):\n",
    "        self.thought_process.append(thought)\n",
    "        if len(self.thought_process) > self.max_thoughts:\n",
    "            self.thought_process.pop(0)\n",
    "            \n",
    "    def clear(self):\n",
    "        self.thought_process = []\n",
    "        \n",
    "    def get_formatted(self) -> str:\n",
    "        thoughts_str = \"\\n\".join([f\"{i+1}. {thought}\" for i, thought in enumerate(self.thought_process)])\n",
    "        return f\"## WORKING MEMORY - CURRENT REASONING PROCESS\\n{thoughts_str}\"\n",
    "\n",
    "class ProspectiveMemory:\n",
    "    def __init__(self):\n",
    "        self.considerations: List[str] = []\n",
    "        \n",
    "    def add_consideration(self, consideration: str):\n",
    "        self.considerations.append(consideration)\n",
    "        \n",
    "    def get_formatted(self) -> str:\n",
    "        if not self.considerations:\n",
    "            return \"## PROSPECTIVE MEMORY - FUTURE CONSIDERATIONS\\nNo specific future considerations at this time.\"\n",
    "        considerations_str = \"\\n\".join([f\"- {consideration}\" for consideration in self.considerations])\n",
    "        return f\"## PROSPECTIVE MEMORY - FUTURE CONSIDERATIONS\\n{considerations_str}\"\n",
    "\n",
    "# --- The main LLM Agent ---\n",
    "\n",
    "class LLMAgent:\n",
    "    def __init__(self, model_name=\"gpt-3.5-turbo\"):\n",
    "        self.sensory_memory = SensoryMemory()\n",
    "        self.short_term_memory = ShortTermMemory()\n",
    "        self.procedural_memory = ProceduralMemory()\n",
    "        self.long_term_memory = LongTermMemory()\n",
    "        self.autobiographical_memory = AutobiographicalMemory()\n",
    "        self.working_memory = WorkingMemory()\n",
    "        self.prospective_memory = ProspectiveMemory()\n",
    "        self.llm = ChatOpenAI(model_name=model_name, temperature=0.7)\n",
    "        self.system_prompt = (\n",
    "            \"You are an advanced AI financial analyst with multiple memory systems.\\n\"\n",
    "            \"Your goal is to provide investment recommendations based on news and price data.\\n\"\n",
    "            \"As you process information, you will build knowledge and learn from your past decisions.\\n\"\n",
    "            \"Think step by step and show your reasoning process before making final recommendations.\\n\"\n",
    "        )\n",
    "\n",
    "    def _build_full_prompt(self, query: str) -> str:\n",
    "        prompt_parts = [\n",
    "            self.sensory_memory.get_formatted(),\n",
    "            self.short_term_memory.get_formatted(),\n",
    "            self.procedural_memory.get_formatted(),\n",
    "            self.long_term_memory.get_formatted(),\n",
    "            self.autobiographical_memory.get_formatted(),\n",
    "            self.working_memory.get_formatted(),\n",
    "            self.prospective_memory.get_formatted(),\n",
    "            f\"\\n## NEW QUERY\\n{query}\\n\\n## RESPONSE\\nLet me think through this step by step:\"\n",
    "        ]\n",
    "        return \"\\n\\n\".join(prompt_parts)\n",
    "    \n",
    "    def react_step(self, query: str) -> str:\n",
    "        full_prompt = self._build_full_prompt(query)\n",
    "        response = self.llm.invoke([HumanMessage(content=full_prompt)])\n",
    "        self.working_memory.add_thought(response.content)\n",
    "        return response.content\n",
    "    \n",
    "    def make_recommendation(self, query: str) -> Decision:\n",
    "        self.working_memory.clear()\n",
    "        self.react_step(f\"Analyze the latest news and price data to answer: {query}\")\n",
    "        recommendation_prompt = f\"\"\"\n",
    "Based on your previous analysis, make a final recommendation regarding: {query}\n",
    "\n",
    "Your response should be structured as:\n",
    "RECOMMENDATION: [Clear statement of recommendation]\n",
    "CONFIDENCE: [Numeric value between 0-1]\n",
    "REASONING: [Concise summary of key factors that led to this recommendation]\n",
    "\"\"\"\n",
    "        full_prompt = self._build_full_prompt(recommendation_prompt)\n",
    "        recommendation_response = self.llm.invoke([HumanMessage(content=full_prompt)])\n",
    "        response_text = recommendation_response.content\n",
    "        \n",
    "        recommendation = \"\"\n",
    "        confidence = 0.5  # Default\n",
    "        reasoning = \"\"\n",
    "        for line in response_text.split('\\n'):\n",
    "            if line.startswith(\"RECOMMENDATION:\"):\n",
    "                recommendation = line.replace(\"RECOMMENDATION:\", \"\").strip()\n",
    "            elif line.startswith(\"CONFIDENCE:\"):\n",
    "                confidence_str = line.replace(\"CONFIDENCE:\", \"\").strip()\n",
    "                try:\n",
    "                    confidence = float(confidence_str)\n",
    "                except ValueError:\n",
    "                    if \"high\" in confidence_str.lower():\n",
    "                        confidence = 0.8\n",
    "                    elif \"medium\" in confidence_str.lower():\n",
    "                        confidence = 0.5\n",
    "                    elif \"low\" in confidence_str.lower():\n",
    "                        confidence = 0.3\n",
    "            elif line.startswith(\"REASONING:\"):\n",
    "                reasoning = line.replace(\"REASONING:\", \"\").strip()\n",
    "                \n",
    "        decision = Decision(\n",
    "            recommendation=recommendation,\n",
    "            confidence=confidence,\n",
    "            reasoning=reasoning\n",
    "        )\n",
    "        self.autobiographical_memory.add_decision(decision)\n",
    "        return decision\n",
    "    \n",
    "    def process_feedback(self, decision_id: str, outcome: str, reward: float):\n",
    "        self.autobiographical_memory.update_outcome(decision_id, outcome, reward)\n",
    "        feedback_prompt = f\"\"\"\n",
    "I received feedback on my recommendation (ID: {decision_id}):\n",
    "Outcome: {outcome}\n",
    "Reward: {reward}\n",
    "\n",
    "Based on this feedback, what's one important fact I should remember for future decisions?\n",
    "Format your response as:\n",
    "NEW FACT: [concise statement of a fact to remember]\n",
    "CATEGORY: [category for this fact]\n",
    "CONFIDENCE: [numeric value between 0-1]\n",
    "\"\"\"\n",
    "        full_prompt = self._build_full_prompt(feedback_prompt)\n",
    "        learning_response = self.llm.invoke([HumanMessage(content=full_prompt)])\n",
    "        response_text = learning_response.content\n",
    "        \n",
    "        fact_text = \"\"\n",
    "        category = \"general\"\n",
    "        confidence = 0.5\n",
    "        for line in response_text.split('\\n'):\n",
    "            if line.startswith(\"NEW FACT:\"):\n",
    "                fact_text = line.replace(\"NEW FACT:\", \"\").strip()\n",
    "            elif line.startswith(\"CATEGORY:\"):\n",
    "                category = line.replace(\"CATEGORY:\", \"\").strip()\n",
    "            elif line.startswith(\"CONFIDENCE:\"):\n",
    "                try:\n",
    "                    confidence = float(line.replace(\"CONFIDENCE:\", \"\").strip())\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        \n",
    "        if fact_text:\n",
    "            new_fact = Fact(\n",
    "                fact=fact_text,\n",
    "                source=f\"Feedback on decision {decision_id}\",\n",
    "                confidence=confidence,\n",
    "                category=category\n",
    "            )\n",
    "            self.long_term_memory.add_fact(new_fact)\n",
    "            self.prospective_memory.add_consideration(\n",
    "                f\"Consider the outcome of similar situations to decision {decision_id} ({fact_text})\"\n",
    "            )\n",
    "        return learning_response.content\n",
    "    \n",
    "    def update_with_news(self, news_items: List[NewsItem]):\n",
    "        for item in news_items:\n",
    "            self.sensory_memory.add_news(item)\n",
    "            self.short_term_memory.add_news(item)\n",
    "    \n",
    "    def update_with_prices(self, price_data: List[PriceData]):\n",
    "        for item in price_data:\n",
    "            self.sensory_memory.add_price(item)\n",
    "            self.short_term_memory.add_price(item)\n",
    "\n",
    "# --- New Function: Update Agent with DataFrame ---\n",
    "\n",
    "def update_agent_with_dataframe(agent: LLMAgent, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    For each row in the DataFrame, creates:\n",
    "      - A NewsItem (using 'text' for content and 'date' for news date)\n",
    "      - A PriceData with all columns (maps 'close' as the main price for asset \"BTC\")\n",
    "    \n",
    "    The news items are added to both sensory and short-term memory, and the price data\n",
    "    (including additional fields) are similarly added.\n",
    "    \"\"\"\n",
    "    news_items = []\n",
    "    price_items = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        # Create news item\n",
    "        news_item = NewsItem(\n",
    "            content=row[\"text\"],\n",
    "            date=row[\"date\"],\n",
    "            source=\"Crypto News\",  # Default; adjust as needed\n",
    "            category=\"Crypto\"      # Default category; adjust as needed\n",
    "        )\n",
    "        # Create price data item with all available fields\n",
    "        price_item = PriceData(\n",
    "            asset=\"BTC\",  # Assuming the asset is Bitcoin\n",
    "            price=float(row[\"close\"]),\n",
    "            date=row[\"date\"],\n",
    "            open=float(row[\"open\"]) if pd.notna(row[\"open\"]) else None,\n",
    "            high=float(row[\"high\"]) if pd.notna(row[\"high\"]) else None,\n",
    "            low=float(row[\"low\"]) if pd.notna(row[\"low\"]) else None,\n",
    "            volume=float(row[\"volume\"]) if pd.notna(row[\"volume\"]) else None,\n",
    "            next_t_close=float(row[\"next_t_close\"]) if pd.notna(row[\"next_t_close\"]) else None,\n",
    "            close_7=float(row[\"close_7\"]) if pd.notna(row[\"close_7\"]) else None,\n",
    "            close_30=float(row[\"close_30\"]) if pd.notna(row[\"close_30\"]) else None,\n",
    "            close_90=float(row[\"close_90\"]) if pd.notna(row[\"close_90\"]) else None,\n",
    "            target=str(row[\"target\"]) if pd.notna(row[\"target\"]) else None,\n",
    "            diff_perc=float(row[\"diff_perc\"]) if pd.notna(row[\"diff_perc\"]) else None\n",
    "        )\n",
    "        news_items.append(news_item)\n",
    "        price_items.append(price_item)\n",
    "    \n",
    "    agent.update_with_news(news_items)\n",
    "    agent.update_with_prices(price_items)\n",
    "\n",
    "# --- Reward Function ---\n",
    "\n",
    "def compute_reward(target: str, diff_perc: float) -> float:\n",
    "    \"\"\"\n",
    "    Computes reward based on the actual outcome.\n",
    "    The higher the diff_perc, the lower the reward.\n",
    "    For example, we use: reward = max(0, 1 - diff_perc/10)\n",
    "    \"\"\"\n",
    "    return max(0.0, 1 - diff_perc / 10)\n",
    "\n",
    "# --- Simulation Example ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a sample DataFrame from your updated data.\n",
    "    data = {\n",
    "        \"date\": [\n",
    "            \"2019-01-03 17:00:00\", \n",
    "            \"2019-01-03 17:00:00\", \n",
    "            \"2019-01-03 18:00:00\", \n",
    "            \"2019-01-03 18:00:00\", \n",
    "            \"2019-01-03 19:00:00\"\n",
    "        ],\n",
    "        \"text\": [\n",
    "            \"Title:\\n Bitcoin Blockchain – Experts Commen...\",\n",
    "            \"Title:\\n Overstock Will Pay Some of Its 2019 T...\",\n",
    "            \"Title:\\n How did cryptocurrency fare in 2018? ...\",\n",
    "            \"Title:\\n Trader: Bitcoin May See Long-Lasting ...\",\n",
    "            \"Title:\\n BTC Genesis Block – Major Milestone...\"\n",
    "        ],\n",
    "        \"timestamp\": [\n",
    "            \"2019-01-03 17:00:00\", \n",
    "            \"2019-01-03 17:00:00\", \n",
    "            \"2019-01-03 18:00:00\", \n",
    "            \"2019-01-03 18:00:00\", \n",
    "            \"2019-01-03 19:00:00\"\n",
    "        ],\n",
    "        \"open\": [3741.61, 3741.61, 3751.29, 3751.29, 3758.70],\n",
    "        \"high\": [3761.94, 3761.94, 3759.56, 3759.56, 3764.60],\n",
    "        \"low\": [3735.22, 3735.22, 3741.54, 3741.54, 3746.75],\n",
    "        \"close\": [3751.29, 3751.29, 3758.70, 3758.70, 3757.09],\n",
    "        \"volume\": [7609.91, 7609.91, 5130.42, 5130.42, 4018.77],\n",
    "        \"next_t_close\": [3981.20, 3981.20, 3981.20, 3979.35, 3991.13],\n",
    "        \"close_7\": [3756.50, 3748.524286, 3750.965714, 3753.407143, 3754.235714],\n",
    "        \"close_30\": [3798.495000, 3796.037333, 3793.662333, 3792.025333, 3790.334667],\n",
    "        \"close_90\": [3789.307000, 3789.958556, 3790.692444, 3791.432000, 3792.153667],\n",
    "        \"target\": [\"Long\", \"Long\", \"Long\", \"Long\", \"Long\"],\n",
    "        \"diff_perc\": [6.128825, 6.128825, 5.919600, 5.870381, 6.229289]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Initialize the agent.\n",
    "    agent = LLMAgent()\n",
    "    \n",
    "    # Update the agent with the DataFrame.\n",
    "    update_agent_with_dataframe(agent, df)\n",
    "    \n",
    "    # Make a recommendation based on the updated data.\n",
    "    print(\"MAKING RECOMMENDATION BASED ON THE PROVIDED DATAFRAME\")\n",
    "    decision = agent.make_recommendation(\"Should investors consider increasing their allocation to Bitcoin?\")\n",
    "    \n",
    "    print(f\"\\nRECOMMENDATION: {decision.recommendation}\")\n",
    "    print(f\"CONFIDENCE: {decision.confidence}\")\n",
    "    print(f\"REASONING: {decision.reasoning}\")\n",
    "    print(f\"DECISION ID: {decision.decision_id}\")\n",
    "    \n",
    "    # --- Simulate Feedback ---\n",
    "    # For demonstration, we pick the last row from the DataFrame as the actual outcome.\n",
    "    outcome_row = df.iloc[-1]\n",
    "    actual_target = outcome_row[\"target\"]\n",
    "    diff_perc = float(outcome_row[\"diff_perc\"])\n",
    "    reward = compute_reward(actual_target, diff_perc)\n",
    "    \n",
    "    # Use outcome details (here we include the target and diff percentage in the outcome string)\n",
    "    outcome_description = f\"Actual outcome was {actual_target} with a diff_perc of {diff_perc:.2f}.\"\n",
    "    \n",
    "    print(\"\\nPROCESSING FEEDBACK BASED ON ACTUAL OUTCOME\")\n",
    "    learning_output = agent.process_feedback(decision_id=decision.decision_id, outcome=outcome_description, reward=reward)\n",
    "    \n",
    "    print(f\"\\nLEARNING OUTPUT: {learning_output}\")\n",
    "    \n",
    "    # (Optional) Visualize the agent's decision history.\n",
    "    decisions = agent.autobiographical_memory.decisions\n",
    "    if decisions:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        decision_ids = [d.decision_id[-6:] for d in decisions]  # Shortened IDs for display\n",
    "        confidence_values = [d.confidence for d in decisions]\n",
    "        rewards = [d.reward if d.reward is not None else 0 for d in decisions]\n",
    "        \n",
    "        bar_width = 0.35\n",
    "        index = range(len(decisions))\n",
    "        \n",
    "        plt.bar([i - bar_width/2 for i in index], confidence_values, bar_width, label='Confidence')\n",
    "        plt.bar([i + bar_width/2 for i in index], rewards, bar_width, label='Reward')\n",
    "        \n",
    "        plt.xlabel('Decisions')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title('Agent Decision Confidence vs Rewards')\n",
    "        plt.xticks(index, decision_ids)\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
